{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Ch. 3. Parallel Algorithms"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## I. Trivially Parallelizable Algorithms\n",
    "In order to properly make use of an HPC system or other parallel computing environment, you need to be able to make your code able to run in parallel. As we saw with our monte carlo pi example, even making the same algorithm run in parallel can make huge changes in terms of performance. If a job running on an HPC system has access to hundreds of cores, but is only written to run in serial, it will not make use of the computational resources it has available to it. In theory, if your task is completely parallelizable, then if you scale it up by a factor of _n_ cores, it will speed up _n_ times. That is to say, if you run a completely parallelizable job on 20 cores, it will run up to 20 times faster than on one core. A graph of this is below: ![Theoretical maximum speedup](https://cdn.comsol.com/wordpress/2014/03/Graph-depicting-how-the-size-of-the-job-increases-with-the-number-of-available-processes.png)\n",
    "This graphic represents the theoretical maximum speedup of various types of HPC jobs, where the x-axis represents the number of cores the job is run on, the y axis represents how much faster the job runs (i.e. if the y-value is 20, the job is 20 times faster than single core), and the value of _phi_ represents the fraction of the job that can be parallelized. The mathematical principle this is based on is called [The Gustafson-Barsis Law](https://en.wikipedia.org/wiki/Gustafson%27s_law)\n",
    "\n",
    "The class of algorithms for which the value of _phi_ is 1, that is to say the class of algorithms that scale perfectly, is known as the \"trivially parallelizable\" class. This means that you can expect linear performance scaling as you increase number of cores linearly. These algorithms are, rather unsurprisingly, very easy to make parallel. Because of this, people using HPC systems often try to reduce their workloads to different \"building blocks\" made up of trivially parallelizable algorithms. A Trivially parallelizable algorithm is defined by task-independence. That is to say, if you break up an algorithm into tasks, in order for that algorithm to be trivially parallelizable, each task must not depend on the output of any other task. The image below represents a trivially parallelizable algorithm:\n",
    "![trivially parallel](http://matthewrocklin.com/slides/images/embarrassing-process.png)\n",
    "Each set of input data goes into a process, and comes out changed. None of them depend on what is happening in other simultaneous processes."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Example 3.1 - Generation of Data\n",
    "As an example of a trivially parallelizable algorithm, we are going to generate lots of numbers in serial and in parallel. This will also teach you a very practical skill with python's `multiprocessing` library: how to \"unroll\" a trivially parallelizable loop into processes that can run simultaneously."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10000000\n",
      "CPU times: user 6.03 s, sys: 699 ms, total: 6.73 s\n",
      "Wall time: 6.25 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# Generating numbers in serial\n",
    "\n",
    "with open(\"/home/users/glick/intro-to-hpc/data/datagen.out\" ,\"w\") as file:\n",
    "    # Printing numbers to file\n",
    "    for i in range(1,10000001):\n",
    "        file.write(str(i)+'\\n')\n",
    "        \n",
    "with open(\"/home/users/glick/intro-to-hpc/data/datagen.out\") as file:\n",
    "    # Reading numbers from file. Don't print them all out because there're too many\n",
    "    print(len(file.readlines()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 4.04 s, sys: 2.58 s, total: 6.62 s\n",
      "Wall time: 4.58 s\n",
      "89273\n"
     ]
    }
   ],
   "source": [
    "# Generating numbers in parallel\n",
    "\n",
    "from multiprocessing import Pool\n",
    "import time\n",
    "file = open(\"/home/users/glick/intro-to-hpc/data/datagenparallel.out\" ,\"w\")\n",
    "\n",
    "# We simply replace the for loop with a function...\n",
    "def process_single(i):\n",
    "    file.write(str(i)+'\\n')\n",
    "\n",
    "# Create a multiprocessing Pool\n",
    "pool = Pool(32)\n",
    "\n",
    "#... And then map our inputs to it as follows:\n",
    "tasks = [pool.apply_async(process_single, (j,)) for j in range(1,100001)]\n",
    "\n",
    "# We use the `get()` function of the last submitted task to time how long it takes to run the process\n",
    "%time tasks[-1].get()\n",
    "\n",
    "#Clean up the files\n",
    "time.sleep(3)\n",
    "file.close()\n",
    "\n",
    "with open(\"/home/users/glick/intro-to-hpc/data/datagenparallel.out\") as file2:\n",
    "    # Reading numbers from file. Don't print them all out because there're too many\n",
    "    print(len(file2.readlines()))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can see that writing the code in parallel is not much more complex than writing it in serial. In this case, the task is carried out so quickly in serial that it is not really worth it to parallelize, but there are a multitude of real-life scenarios where a workflow, or at least part of a workflow is trivially parallelizable and it makes sense to do so."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## II. Monte Carlo Simulations"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Example 3.2 - Monte Carlo Frog Hop Simulation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## III. Single Instruction, Multiple Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Example 3.3 - Vector Addition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## IV. Multiple Instruction, Multiple Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Example 3.4 - Asynchronous Branching Logic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## V. Concurrency vs. Parallelism"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Example 3.5a - Downloading and IO-Bound Tasks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Example 3.5b - Data Generation and CPU-Bound Tasks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## VI. Dataflows"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Example 3.6 - `sleep_fail` dataflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercise 3. Write a dataflow that estimates the value of _e_ "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  },
  "latex_envs": {
   "LaTeX_envs_menu_present": true,
   "autoclose": false,
   "autocomplete": true,
   "bibliofile": "biblio.bib",
   "cite_by": "apalike",
   "current_citInitial": 1,
   "eqLabelWithNumbers": true,
   "eqNumInitial": 1,
   "hotkeys": {
    "equation": "Ctrl-E",
    "itemize": "Ctrl-I"
   },
   "labels_anchors": false,
   "latex_user_defs": false,
   "report_style_numbering": false,
   "user_envs_cfg": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
