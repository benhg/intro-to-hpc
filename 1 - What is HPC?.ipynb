{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Ch. 1. Introduction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## I. What is High-Performance Computing?\n",
    "\n",
    "Most people believe that High-Performance Computing (HPC) is defined by the architecture of the computer it runs on. In standard computing, one physical computer with one or more cores is used to carry out a task. All of these cores can access a pool of [Shared Memory](https://en.wikipedia.org/wiki/Shared_memory). Shared memory makes it trivial for two or more programs or parts of a single program to understand what other programs are doing. The following diagram represents a multicore single computer working in this fashion: ![multicore architecture diagram](https://i.pinimg.com/originals/22/31/f8/2231f856a5341e19526d089e1ffbe630.jpg \"Logo Title Text 1\")\n",
    "On the other hand, most high performance systems are clusters which consist of many separate multicore computers which are all connected over a network. In this configuration, the individual parts of a program running on separate physical machines are not easily able to communicate without connecting over the network. The following diagram represents a cluster of multicore computers working as a single cluster:  ![HPC cluster architecture diagram](http://cialisalto.com/wp-content/uploads/2018/01/excellent-hpc-cluster-architecture-on-and-contemporary-with-data-5.jpg \"Logo Title Text 1\")\n",
    "\n",
    "Because of the dependence on networking, programming for HPC environments requires special considerations that normal programming does not."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Example 1.1 - Computing Pi on a Standard Computer\n",
    "As an example of \"traditional\" computation, we will now compute the numerical value of Pi through the monte carlo simulation method.\n",
    "\n",
    "Monte carlo simulations are a class of computational algorithms that rely on repeated random sampling to obtain numerical results. We will discuss them in more detail in the parallel algorithms notebook. A very common monte carlo simulation uses some basic geometry to estimate the numerical value of pi. \n",
    "\n",
    "For this, we imagine a circle of radius 1 inscribed in a square. Then, we choose random points in the square, and classify them by whether they are inside the circle or outside. This gives us an estimate of the areas of the square and the circle. Then, we take the ratio of one to the other and we have an estimation of pi. If this doesn't make any sense to you, don't worry. This image may help you understand a bit better: ![Monte Carlo Pi](https://ds055uzetaobb.cloudfront.net/image_optimizer/aabd5727316301f18f53bd4cbc63914fed0bcb2c.gif \"Logo Title Text 1\")\n",
    "In the example below, we calculate pi by monte carlo simulation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Esitmated value of Pi: 3.1344 \n"
     ]
    }
   ],
   "source": [
    "# Monte Carlo Pi Simulation\n",
    "import random as r\n",
    "import math as m\n",
    "\n",
    "# Number of darts that land inside.\n",
    "inside = 0\n",
    "# Total number of darts to throw.\n",
    "total = 10000\n",
    "\n",
    "# Iterate for the number of darts.\n",
    "for i in range(0, total):\n",
    "    # Generate random x, y in [0, 1].\n",
    "    x2 = r.random()**2\n",
    "    y2 = r.random()**2\n",
    "    # Increment if inside unit circle.\n",
    "    if m.sqrt(x2 + y2) < 1.0:\n",
    "        inside += 1\n",
    "\n",
    "# inside / total = pi / 4\n",
    "pi = (float(inside) / total) * 4\n",
    "\n",
    "print(\"Esitmated value of Pi: {} \".format(pi))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## II. Why is HPC important?\n",
    "High performance computing opens the door to large scale data analysis, computational science, and research computing. It is useful in a number of scenarios, including where software is too time-critical, too performance critical, or simply too big to run on a traditional system.\n",
    "\n",
    "Let's take a look at a few examples of scenarios where you would need an HPC System or an HPC System drastically changes your process.\n",
    "\n",
    "- **Scenario 1: Real-Time App:** Let's imagine you're an app developer working for The Weather Channel. You want to make an app that automatically detects where a person is, very specifically, and then uses your complex AccuWeather analysis to predict the likelihood of rain any time in the next seven days for that specific location. You would like your user to be able to get this data within seconds. There is no way you will be able to serve this user, let alone your millions of other users, this data with a single traditional computer. Having an HPC system available here is extremely important, in order to ensure your users get their weather in close to real time. ![Weather Models](http://aemstatic-ww1.azureedge.net/content/ias/en/articles/2012/08/honeywell-3d/_jcr_content/leftcolumn/article/headerimage.img.jpg/1345596242801.jpg \"\")\n",
    "- **Scenario 2: Designing a New Car or Plane:** You're a brand new aerospace engineer working for the Mercedes-Benz Formula One team. You have the off season (usually between December and May, or about five months) to design a new car which is better than all the cars that beat you last year. Traditionally, the way to do this is start with a small model, put it in a wind tunnel, evaluate it, and repeat this process. Then, you slowly scale up to bigger models and eventually start building concept cars. However, you only have five months, and each model may take a month to design and produce. You simply don't have time. Instead, you get started with your HPC system and start creating some [Computational Fluid Dynamics](https://en.wikipedia.org/wiki/Computational_fluid_dynamics) models which you can then use to create your new car with plenty of time to spare. The image below is the output of a CFD model. ![CFD model of car](https://upload.wikimedia.org/wikipedia/commons/f/fa/Verus_Engineering_Porsche_987.2_Ventus_2_Package.png \" \")\n",
    "- **Scenario 3: Computational Climate Research:** Let's say you are a climate scientist. You want to simulate the climate of the entire world. You want to put in what the world was like in 1900, then press the play button, and simulate the entire 1900s in the entire world. Then, you want to compare what that looks like to what actually happened in the 1900s, and finally, if that's good enough, you want to keep playing through until 2100. This is simply too big a task to run on a normal computer; you will be waiting literally for years before your job exits.\n",
    "![computational climate research](https://www.gfdl.noaa.gov/wp-content/uploads/pix/model_development/climate_modeling/climatemodel.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "code_folding": []
   },
   "source": [
    "### Example 1.2 - Multiplying Matrices in Parallel\n",
    "\n",
    "Though it's not as large-scale as either of the examples mentioned above, a very applicable and useful application of parallel programming is matrix multiplication. Runtime of multiplying two _n_ by _n_ matrices is in the complexity class O(_n<sup>3</sup>_). This means that a good parallel algorithm which can make use of multiple cores for this process is very important. An example of a parallel algorithm to multiply matrices is below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Necessary definitions for matrix multiplication\n",
    "import ctypes\n",
    "import multiprocessing\n",
    "import numpy\n",
    "\n",
    "def read(filename):\n",
    "    lines = open(filename, 'r').read().splitlines()\n",
    "    A = []\n",
    "    B = []\n",
    "    matrix = A\n",
    "    for line in lines:\n",
    "        if line != \"\":\n",
    "            matrix.append(map(int, line.split(\"\\t\")))\n",
    "        else:\n",
    "            matrix = B\n",
    "    return A, B\n",
    "\n",
    "def printMatrix(matrix, f):\n",
    "    for line in matrix:\n",
    "        f.write(\"\\t\".join(map(str,line)) + \"\\n\")\n",
    "\n",
    "def lineMult(start):\n",
    "    global A, B, mp_arr, part\n",
    "    n = len(A)\n",
    "    # create a new numpy array using the same memory as mp_arr\n",
    "    arr = numpy.frombuffer(mp_arr.get_obj(), dtype=ctypes.c_int)\n",
    "    C = arr.reshape((n,n))\n",
    "    for i in range(start, start+part):\n",
    "        for k in range(n):\n",
    "            for j in range(n):\n",
    "                C[i][j] += list(A[i])[k] * list(B[k])[j]\n",
    "\n",
    "def ikjMatrixProduct(A, B, threadNumber):\n",
    "    n = len(A)\n",
    "    \n",
    "    pool = multiprocessing.Pool(threadNumber)\n",
    "\n",
    "    pool.map(lineMult, range(0, int(n), int(part)))\n",
    "    # mp_arr and arr share the same memory\n",
    "    arr = numpy.frombuffer(mp_arr.get_obj(), dtype=ctypes.c_int) \n",
    "    C = arr.reshape((n,n))\n",
    "    return C\n",
    "\n",
    "def extant_file(x):\n",
    "    \"\"\"\n",
    "    'Type' for argparse - checks that file exists but does not open.\n",
    "    \"\"\"\n",
    "    if not isfile(x):\n",
    "        raise argparse.ArgumentError(\"{0} does not exist\".format(x))\n",
    "    return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "ename": "IndexError",
     "evalue": "list index out of range",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRemoteTraceback\u001b[0m                           Traceback (most recent call last)",
      "\u001b[0;31mRemoteTraceback\u001b[0m: \n\"\"\"\nTraceback (most recent call last):\n  File \"/local/cluster/lib/python3.6/multiprocessing/pool.py\", line 119, in worker\n    result = (True, func(*args, **kwds))\n  File \"/local/cluster/lib/python3.6/multiprocessing/pool.py\", line 44, in mapstar\n    return list(map(*args))\n  File \"<ipython-input-60-7e5b7c37b560>\", line 31, in lineMult\n    C[i][j] += list(A[i])[k] * list(B[k])[j]\nIndexError: list index out of range\n\"\"\"",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[0;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-61-a4cecc005aad>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     16\u001b[0m \u001b[0;31m# shared, can be used from multiple processes\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     17\u001b[0m \u001b[0mmp_arr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmultiprocessing\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mArray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mctypes\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mc_int\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mp\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 18\u001b[0;31m \u001b[0mC\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mikjMatrixProduct\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mA\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mB\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mthreadNumber\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     19\u001b[0m \u001b[0mprintMatrix\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mC\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msys\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstdout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-60-7e5b7c37b560>\u001b[0m in \u001b[0;36mikjMatrixProduct\u001b[0;34m(A, B, threadNumber)\u001b[0m\n\u001b[1;32m     36\u001b[0m     \u001b[0mpool\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmultiprocessing\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mPool\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mthreadNumber\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     37\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 38\u001b[0;31m     \u001b[0mpool\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmap\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlineMult\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mn\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpart\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     39\u001b[0m     \u001b[0;31m# mp_arr and arr share the same memory\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     40\u001b[0m     \u001b[0marr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnumpy\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfrombuffer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmp_arr\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_obj\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mctypes\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mc_int\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/local/cluster/lib/python3.6/multiprocessing/pool.py\u001b[0m in \u001b[0;36mmap\u001b[0;34m(self, func, iterable, chunksize)\u001b[0m\n\u001b[1;32m    264\u001b[0m         \u001b[0;32min\u001b[0m \u001b[0ma\u001b[0m \u001b[0mlist\u001b[0m \u001b[0mthat\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0mreturned\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    265\u001b[0m         '''\n\u001b[0;32m--> 266\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_map_async\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfunc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0miterable\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmapstar\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mchunksize\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    267\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    268\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mstarmap\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0miterable\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mchunksize\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/local/cluster/lib/python3.6/multiprocessing/pool.py\u001b[0m in \u001b[0;36mget\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    642\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_value\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    643\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 644\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_value\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    645\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    646\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_set\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mobj\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mIndexError\u001b[0m: list index out of range"
     ]
    }
   ],
   "source": [
    "# Run the matrix multiplication\n",
    "\n",
    "import argparse, sys\n",
    "from os.path import isfile\n",
    "from argparse import ArgumentParser\n",
    "\n",
    "A, B = read(\"data/matrix_mult.in\")\n",
    "\n",
    "n, m, p = len(A), len(list(A[0])), len(list(B[0]))\n",
    "\n",
    "threadNumber = 32\n",
    "part = len(A) // threadNumber\n",
    "if part < 1:\n",
    "    part = 1\n",
    "\n",
    "# shared, can be used from multiple processes\n",
    "mp_arr = multiprocessing.Array(ctypes.c_int, n*p)\n",
    "C = ikjMatrixProduct(A, B, threadNumber)\n",
    "printMatrix(C, sys.stdout)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## III. Multiprocessing\n",
    "One of the reasons this course is written in python is that python is an easy to use language which is commonly used for computational science and other HPC applications. Another reason that Python was chosen for this course is Python's powerful _multiprocessing_ library. _Multiprocessing_ allows users to open subprocesses within python in order to run many different snippets of python code all at once. In the following examples, we will use _multiprocessing_ to speed up our computations. It is true that Python has a GIL (global interpreter lock) which keeps it from natively running truly parallel programs, but with multiprocessing, we can get around this at the expense of heavier RAM overhead. The purpose of this course is not necessarily to write the fastest possible code, but more to demonstrate the techniques, methods, and tools for doing that in the future, and Python is an easily understandable and highly readable language. The following image is a description of how multiprocessing can help speed up Python programs: ![Multiprocessing Diagram](https://sebastianraschka.com/images/blog/2014/multiprocessing_intro/multiprocessing_scheme.png \"\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Example 1.3 - Basic Parallelization with Multiprocessing\n",
    "In this example, we are going to create random strings in parallel and in serial. This is a good task to parallelize because each random string does not depend at all on the random strings that came before it. We will discuss in greater detail what makes tasks better candidates for parallelization in topic 6: algorithm analysis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define rand_string function to generate one random string\n",
    "\n",
    "import random\n",
    "import string\n",
    "import multiprocessing\n",
    "\n",
    "random.seed(123)\n",
    "\n",
    "# Define an output queue\n",
    "output = multiprocessing.Queue()\n",
    "\n",
    "# define a example function\n",
    "def rand_string(length, output):\n",
    "    \"\"\" Generates a random string of numbers, lower and uppercase chars. \"\"\"\n",
    "    rand_str = ''.join(random.choice(\n",
    "                        string.ascii_lowercase\n",
    "                        + string.ascii_uppercase\n",
    "                        + string.digits)\n",
    "                   for i in range(length))\n",
    "    output.put(rand_str)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generated 100 strings in 0.006600379943847656 seconds\n"
     ]
    }
   ],
   "source": [
    "# Call our rand_string in serial\n",
    "\n",
    "import time\n",
    "NUM_STRINGS = 100\n",
    "\n",
    "processes = []\n",
    "before = time.time()\n",
    "for _ in range(NUM_STRINGS):\n",
    "    processes.append(rand_string(5, output))\n",
    "results = [output.get() for p in processes]\n",
    "after = time.time()\n",
    "\n",
    "print(\"Generated {} strings in {} seconds\".format(NUM_STRINGS, after-before))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Generated 100 strings in 0.0017147064208984375 seconds\n"
     ]
    }
   ],
   "source": [
    "# Call our rand_string in parallel\n",
    "\n",
    "import time\n",
    "\n",
    "before = time.time()\n",
    "NUM_STRINGS = 100\n",
    "# Setup a list of processes that we want to run\n",
    "processes = []\n",
    "for _ in range(NUM_STRINGS):\n",
    "    p = multiprocessing.Process(target=rand_string, args=(5, output))\n",
    "    processes.append(p)\n",
    "\n",
    "# Run processes\n",
    "for p in processes:\n",
    "    p.start()\n",
    "\n",
    "# Exit the completed processes\n",
    "for p in processes:\n",
    "    p.join()\n",
    "\n",
    "# Get process results from the output queue\n",
    "before = time.time()\n",
    "results = [output.get() for p in processes]\n",
    "after = time.time()\n",
    "\n",
    "print('\\n')\n",
    "print(\"Generated {} strings in {} seconds\".format(NUM_STRINGS, after-before))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As you can see, the task runs more than five times faster in parallel than it does in serial"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## IV. Parallelism and HPC\n",
    "Parallelism is at the core of any HPC system. The way that HPC systems can be many hundreds of thousands of times faster than traditional systems is through massive parallelism. Some HPC systems have a total of many millions of cores, distributed among many systems (known as 'nodes'), as compared to the 4-8 of a standard modern desktop. This massive hardware parallelism, combined with some clever parallel algorithms, can lead to amazing processing power. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Example 1.4 - Monte Carlo Pi in Parallel\n",
    "In this example, we will compute pi through monte carlo approximation, similar to the way we did it before, except this time we will do it in parallel. As mentioned earlier, the monte carlo pi calculation is a very easily parallelized algorithm, and there should be a large speedup when it is run in parallel."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Defining parallel monte carlo pi calculation \n",
    "\n",
    "import random\n",
    "import multiprocessing\n",
    "from multiprocessing import Pool\n",
    "\n",
    "\n",
    "#caculate the number of points in the unit circle\n",
    "#out of n points\n",
    "def monte_carlo_pi_part(n):\n",
    "    \n",
    "    count = 0\n",
    "    for i in range(n):\n",
    "        x=random.random()\n",
    "        y=random.random()\n",
    "        \n",
    "        # if it is within the unit circle\n",
    "        if x*x + y*y <= 1:\n",
    "            count=count+1\n",
    "        \n",
    "    #return\n",
    "    return count   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "You have 32 CPUs\n",
      "Esitmated value of Pi: 3.1416868 \n"
     ]
    }
   ],
   "source": [
    "# Calling parallel monte carlo pi simulation\n",
    "\n",
    "np = multiprocessing.cpu_count()\n",
    "print('You have {0:1d} CPUs'.format(np))\n",
    "\n",
    "# Nummber of points to use for the Pi estimation\n",
    "n = 10000000\n",
    "\n",
    "# iterable with a list of points to generate in each worker\n",
    "# each worker process gets n/np number of points to calculate Pi from\n",
    "\n",
    "part_count=[n//np for i in range(np)]\n",
    "\n",
    "# Create the worker pool\n",
    "# http://docs.python.org/library/multiprocessing.html#module-multiprocessing.pool\n",
    "pool = Pool(processes=np)   \n",
    "\n",
    "# parallel map\n",
    "count=pool.map(monte_carlo_pi_part, part_count)\n",
    "\n",
    "print(\"Esitmated value of Pi: {} \".format(sum(count)/(n*1.0)*4))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## V. Power and Speed Comparison\n",
    "One definition of HPC has to do with scale. Some people believe that an HPC system is defined by how powerful it is rather than by how it is designed. Computational power has increased an incredible amount recently and HPC scale systems are now easily accessible to many people. The following graphic shows how powerful modern systems can be: ![hpc system power comparison](https://i.imgur.com/frXsxpz.png)\n",
    "\n",
    "As you might guess, parallel algorithms have the potential to be much faster than serial algorithms. In order to show this, we are going to use the two versions of monte carlo pi that we have designed in this notebook and time them against each other. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Example 1.5 - Pi in Serial vs Parallel\n",
    "In this example, we will pit against each other our parallel and serial pi approximation calculations. To do this, we will use the jupyter \"magic\" `%%time` to time the two algorithms."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Defining parallel monte carlo pi calculation \n",
    "\n",
    "import random\n",
    "import multiprocessing\n",
    "from multiprocessing import Pool\n",
    "\n",
    "\n",
    "#caculate the number of points in the unit circle\n",
    "#out of n points\n",
    "def monte_carlo_pi_part(n):\n",
    "    \n",
    "    count = 0\n",
    "    for i in range(n):\n",
    "        x=random.random()\n",
    "        y=random.random()\n",
    "        \n",
    "        # if it is within the unit circle\n",
    "        if x*x + y*y <= 1:\n",
    "            count=count+1\n",
    "        \n",
    "    #return\n",
    "    return count  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Esitmated value of Pi: 3.1420784 \n",
      "CPU times: user 82.4 ms, sys: 622 ms, total: 704 ms\n",
      "Wall time: 947 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "# Calling parallel monte carlo pi simulation\n",
    "\n",
    "# Nummber of points to use for the Pi estimation\n",
    "n = 10000000\n",
    "\n",
    "# iterable with a list of points to generate in each worker\n",
    "# each worker process gets n/np number of points to calculate Pi from\n",
    "\n",
    "part_count=[n//np for i in range(np)]\n",
    "\n",
    "#Create the worker pool\n",
    "# http://docs.python.org/library/multiprocessing.html#module-multiprocessing.pool\n",
    "pool = Pool(processes=np)   \n",
    "\n",
    "# parallel map\n",
    "count=pool.map(monte_carlo_pi_part, part_count)\n",
    "\n",
    "print(\"Esitmated value of Pi: {} \".format(sum(count)/(n*1.0)*4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Esitmated value of Pi: 3.1413032 \n",
      "CPU times: user 7.45 s, sys: 276 ms, total: 7.73 s\n",
      "Wall time: 7.23 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "# Calling serial monte carlo pi simulation\n",
    "# Monte Carlo Pi Simulation\n",
    "import random as r\n",
    "import math as m\n",
    "\n",
    "# Number of darts that land inside.\n",
    "inside = 0\n",
    "# Total number of darts to throw.\n",
    "total = 10000000\n",
    "\n",
    "# Iterate for the number of darts.\n",
    "for i in range(0, total):\n",
    "    # Generate random x, y in [0, 1].\n",
    "    x2 = r.random()**2\n",
    "    y2 = r.random()**2\n",
    "    # Increment if inside unit circle.\n",
    "    if m.sqrt(x2 + y2) < 1.0:\n",
    "        inside += 1\n",
    "\n",
    "# inside / total = pi / 4\n",
    "pi = (float(inside) / total) * 4\n",
    "\n",
    "print(\"Esitmated value of Pi: {} \".format(pi))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## VI. HPC Architecture\n",
    "As mentioned earlier, an HPC system is generally not just one machine, instead it is a set of individual computers networked together. This network is similar in concept to the Internet, though it is usually much faster and the network topology (the way the computers are organized in relation to each other) is different. In the case of the cluster this course is running on, the network is a bus topology, meaning that all of the nodes are plugged into a single network switch. The graphic below illustrates some common network topologies:\n",
    "![Network Topologies](https://static9.depositphotos.com/1389325/1074/v/950/depositphotos_10743280-stock-illustration-illustration-of-network-topology-computer.jpg)\n",
    "\n",
    "With multiple computers working together, HPC systems are able to achieve massive performance. The fastest system in the world is a cluster like this which runs at a peak of roughly 200 Petaflops, or 200 quadrillion floating point operations per second. Because these systems have programs that take up more than a whole node, they need a way to understand which parts of programs are running on which nodes. The way this is usually handled is through inter-process communication. We will get into this concept more in topic 5: distributed algorithms, but essentially, one part of a program will send a message to another part of the same program and tell it what information it needs to know in order to do its job. The following image describes this process:\n",
    "![Message Passing Diagram](https://computing.llnl.gov/tutorials/mpi/images/collective_comm.gif)\n",
    "\n",
    "In the image labeled \"broadcast\", a message-passing task is sending a message to all other running tasks. This can be useful to orchestrate many copies of the same program. In the image labeled \"scatter\", the task sends a personalized message to each other running task. this is useful when the same instruction needs to be performed with different input data. In the images labeled \"gather\" and \"reduction,\" the task receives messages from all other tasks and creates a summary of all the input data. This can be used in situations where data is generated by one part of a workflow and needs to be processed later. Please keep in mind that there are many more applications of inter-process communication. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Example 1.6 - Pinging Other Nodes \n",
    "\"You're not alone out there\"\n",
    "\n",
    "As an example of a task involving many nodes, we're going to check around in our network and see if any other compute nodes are accessible or available. To do this, we're going to use Python's `subprocess` module to interact with the operating system."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Defining ping function\n",
    "\n",
    "def ping(host):\n",
    "    \"\"\"\n",
    "    Returns True if host responds to a ping request\n",
    "    \"\"\"\n",
    "    import subprocess, platform\n",
    "\n",
    "    # Ping parameters as function of OS\n",
    "    ping_str = \"-n 1\" if  platform.system().lower()==\"windows\" else \"-c 1\"\n",
    "    args = \"ping -i 0.2 \" + \" \" + ping_str + \" \" + host\n",
    "\n",
    "    # Ping\n",
    "    return subprocess.call(args, shell=True) == 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "192.168.0.1\n",
      "192.168.0.101\n",
      "192.168.0.102\n",
      "192.168.0.103\n"
     ]
    }
   ],
   "source": [
    "# Ping all addresses in our 172.16.52.0/24 network and print ones that seem up\n",
    "for j in range(0, 256):\n",
    "    host = \"192.168.0.{}\".format(j)\n",
    "    res = ping(host)\n",
    "    if res:\n",
    "        print(host)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If you waited long enough (and i don't blame you if you didn't) you will have seen that there are four machines up in this network, which could grow to a size of 255."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercise 1. Write a program to compute sums of _n_ integers in parallel "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Your code goes here"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  },
  "latex_envs": {
   "LaTeX_envs_menu_present": true,
   "autoclose": false,
   "autocomplete": true,
   "bibliofile": "biblio.bib",
   "cite_by": "apalike",
   "current_citInitial": 1,
   "eqLabelWithNumbers": true,
   "eqNumInitial": 1,
   "hotkeys": {
    "equation": "Ctrl-E",
    "itemize": "Ctrl-I"
   },
   "labels_anchors": false,
   "latex_user_defs": false,
   "report_style_numbering": false,
   "user_envs_cfg": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
