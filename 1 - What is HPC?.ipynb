{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## I.What is High-Performance Computing?\n",
    "\n",
    "Most people believe that High-Performance Computing (HPC) is defined by the architecture of the computer it runs on. In standard computing, one physical computer with one or more cores is used to carry out a task. All of these cores can access a pool of [Shared Memory](https://en.wikipedia.org/wiki/Shared_memory). Shared memory makes it trivial for two or more programs or parts of a single program to understand what other programs are doing. The following diagram represents a multicore single computer working in this fashion: ![multicore architecture diagram](https://i.pinimg.com/originals/22/31/f8/2231f856a5341e19526d089e1ffbe630.jpg \"Logo Title Text 1\")\n",
    "On the other hand, most high performance systems are clusters which consist of many separate multicore computers which are all connected over a network. In this configuration, the individual parts of a program running on separate physical machines are not easily able to communicate without connecting over the network. The following diagram represents a cluster of multicore computers working as a single cluster:  ![HPC cluster architecture diagram](http://cialisalto.com/wp-content/uploads/2018/01/excellent-hpc-cluster-architecture-on-and-contemporary-with-data-5.jpg \"Logo Title Text 1\")\n",
    "\n",
    "Because of the dependence on networking, programming for HPC environments requires special considerations that normal programming does not."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Example 1.1 - computing pi on a standard computer\n",
    "As an example of \"traditional\" computation, we will now compute the numerical value of Pi through the monte carlo simulation method.\n",
    "\n",
    "Monte carlo simulations are a class of computational algorithms that rely on repeated random sampling to obtain numerical results. We will discuss them in more detail in the parallel algorithms notebook. A very common monte carlo simulation uses some basic geometry to estimate the numerical value of pi. \n",
    "\n",
    "For this, we imagine a circle of radius 1 inscribed in a square. Then, we choose random points in the square, and classify \"them by whether they are inside the circle or outside. This gives us an estimate of the areas of the square and the circle. Then, we take the ratio of one to the other and we have an estimation of pi. If this doesn't make any sense to you, don't worry. This image may help you understand a bit better: ![Monte Carlo Pi](https://ds055uzetaobb.cloudfront.net/image_optimizer/aabd5727316301f18f53bd4cbc63914fed0bcb2c.gif \"Logo Title Text 1\")\n",
    "In the example below, we calculate pi by monte carlo simulation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Monte Carlo Pi Simulation\n",
    "import random as r\n",
    "import math as m\n",
    "\n",
    "# Number of darts that land inside.\n",
    "inside = 0\n",
    "# Total number of darts to throw.\n",
    "total = 10000\n",
    "\n",
    "# Iterate for the number of darts.\n",
    "for i in range(0, total):\n",
    "    # Generate random x, y in [0, 1].\n",
    "    x2 = r.random()**2\n",
    "    y2 = r.random()**2\n",
    "    # Increment if inside unit circle.\n",
    "    if m.sqrt(x2 + y2) < 1.0:\n",
    "        inside += 1\n",
    "\n",
    "# inside / total = pi / 4\n",
    "pi = (float(inside) / total) * 4\n",
    "\n",
    "# It works!\n",
    "print(pi)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## II.Why is HPC important?\n",
    "High performance computing opens the door to large scale data analysis, computational science, and research computing. It is useful in a number of scenarios, including where software is too time-critical, too performance critical, or simply too big to run on a traditional system.\n",
    "\n",
    "Let's take a look at a few examples of scenarios where you would need an HPC System or an HPC System drastically changes your process.\n",
    "\n",
    "- **Scenario 1: Real-Time App:** Let's imagine you're an app developer working for The Weather Channel. You want to make an app that automatically detects where a person is, very specifically, and then uses your complex AccuWeather analysis to predict the likelihood of rain any time in the next seven days for that specific location. You would like your user to be able to get this data within seconds. There is no way you will be able to serve this user, let alone your millions of other users, this data with a single traditional computer. Having an HPC system available here is extremely important, in order to ensure your users get their weather in close to real time. ![Weather Models](http://aemstatic-ww1.azureedge.net/content/ias/en/articles/2012/08/honeywell-3d/_jcr_content/leftcolumn/article/headerimage.img.jpg/1345596242801.jpg \"\")\n",
    "- **Scenario 2: Designing a New Car or Plane:** You're a brand new aerospace engineer working for the Mercedes-Benz Formula One team. You have the off season (usually between December and May, or about five months) to design a new car which is better than all the cars that beat you last year. Traditionally, the way to do this is start with a small model, put it in a wind tunnel, evaluate it, and repeat this process. Then, you slowly scale up to bigger models and eventually start building concept cars. However, you only have five months, and each model may take a month to design and produce. You simply don't have time. Instead, you get started with your HPC system and start creating some [Computational Fluid Dynamics](https://en.wikipedia.org/wiki/Computational_fluid_dynamics) models which you can then use to create your new car with plenty of time to spare. The image below is the output of a CFD model. ![CFD model of car](https://upload.wikimedia.org/wikipedia/commons/f/fa/Verus_Engineering_Porsche_987.2_Ventus_2_Package.png \" \")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "code_folding": []
   },
   "source": [
    "### Example 1.2 - Multiplying Matrices in Parallel\n",
    "\n",
    "Though it's not as large-scale as either of the examples mentioned above, a very applicable and useful application of parallel programming is matrix multiplication. Runtime of multiplying two _n_ by _n_ matrices is in complexity class O(_n<sup>3</sup>_). This means that a good parallel algorithm which can make use of multiple cores for this process is very important. An example of a parallel algorithm to multiply matrices is below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Necessary definitions for matrix multiplication\n",
    "import ctypes\n",
    "import multiprocessing\n",
    "import numpy\n",
    "\n",
    "def read(filename):\n",
    "    lines = open(filename, 'r').read().splitlines()\n",
    "    A = []\n",
    "    B = []\n",
    "    matrix = A\n",
    "    for line in lines:\n",
    "        if line != \"\":\n",
    "            matrix.append(map(int, line.split(\"\\t\")))\n",
    "        else:\n",
    "            matrix = B\n",
    "    return A, B\n",
    "\n",
    "def printMatrix(matrix, f):\n",
    "    for line in matrix:\n",
    "        f.write(\"\\t\".join(map(str,line)) + \"\\n\")\n",
    "\n",
    "def lineMult(start):\n",
    "    global A, B, mp_arr, part\n",
    "    n = len(A)\n",
    "    # create a new numpy array using the same memory as mp_arr\n",
    "    arr = numpy.frombuffer(mp_arr.get_obj(), dtype=ctypes.c_int)\n",
    "    C = arr.reshape((n,n))\n",
    "    for i in range(start, start+part):\n",
    "        for k in range(n):\n",
    "            for j in range(n):\n",
    "                C[i][j] += list(A[i])[k] * list(B[k])[j]\n",
    "\n",
    "def ikjMatrixProduct(A, B, threadNumber):\n",
    "    n = len(A)\n",
    "    \n",
    "    pool = multiprocessing.Pool(threadNumber)\n",
    "\n",
    "    pool.map(lineMult, range(0, int(n), int(part)))\n",
    "    # mp_arr and arr share the same memory\n",
    "    arr = numpy.frombuffer(mp_arr.get_obj(), dtype=ctypes.c_int) \n",
    "    C = arr.reshape((n,n))\n",
    "    return C\n",
    "\n",
    "def extant_file(x):\n",
    "    \"\"\"\n",
    "    'Type' for argparse - checks that file exists but does not open.\n",
    "    \"\"\"\n",
    "    if not isfile(x):\n",
    "        raise argparse.ArgumentError(\"{0} does not exist\".format(x))\n",
    "    return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run the matrix multiplication\n",
    "\n",
    "import argparse, sys\n",
    "from os.path import isfile\n",
    "from argparse import ArgumentParser\n",
    "\n",
    "A, B = read(\"data/matrix_mult.in\")\n",
    "\n",
    "n, m, p = len(A), len(list(A[0])), len(list(B[0]))\n",
    "\n",
    "threadNumber = 32\n",
    "part = len(A) // threadNumber\n",
    "if part < 1:\n",
    "    part = 1\n",
    "\n",
    "# shared, can be used from multiple processes\n",
    "mp_arr = multiprocessing.Array(ctypes.c_int, n*p)\n",
    "C = ikjMatrixProduct(A, B, threadNumber)\n",
    "printMatrix(C, sys.stdout)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## III.Multiprocessing\n",
    "One of the reasons this course is written in python is that python is an easy to use language which is commonly used for computational science and other HPC applications. Another reason that Python was chosen for this course is Python's powerful _multiprocessing_ library. _Multiprocessing_ allows users to open subprocesses within python in order to run many different snippets of python code all at once. In the following examples, we will use _multiprocessing_ to speed up our computations. The following image is a description of how multiprocessing can help speed up Python programs: ![Multiprocessing Diagram](https://sebastianraschka.com/images/blog/2014/multiprocessing_intro/multiprocessing_scheme.png \"\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Example 1.3 - Basic Parallelization with Multiprocessing\n",
    "In this example, we are going to create random strings in parallel and in serial. This is a good task to parallelize because each random string does not depend at all on the random strings that came before it. We will discuss in greater detail what makes tasks better candidates for parallelization in topic 6: algorithm analysis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define rand_string function to generate one random string\n",
    "\n",
    "import random\n",
    "import string\n",
    "import multiprocessing\n",
    "\n",
    "random.seed(123)\n",
    "\n",
    "# Define an output queue\n",
    "output = multiprocessing.Queue()\n",
    "\n",
    "# define a example function\n",
    "def rand_string(length, output):\n",
    "    \"\"\" Generates a random string of numbers, lower- and uppercase chars. \"\"\"\n",
    "    rand_str = ''.join(random.choice(\n",
    "                        string.ascii_lowercase\n",
    "                        + string.ascii_uppercase\n",
    "                        + string.digits)\n",
    "                   for i in range(length))\n",
    "    output.put(rand_str)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Call our rand_string in serial\n",
    "\n",
    "import time\n",
    "NUM_STRINGS = 100\n",
    "\n",
    "processes = []\n",
    "before = time.time()\n",
    "for _ in range(NUM_STRINGS):\n",
    "    processes.append(rand_string(5, output))\n",
    "results = [output.get() for p in processes]\n",
    "after = time.time()\n",
    "\n",
    "print(\"Generated {} strings in {} seconds\".format(NUM_STRINGS, after-before))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Call our rand_string in parallel\n",
    "\n",
    "import time\n",
    "\n",
    "before = time.time()\n",
    "NUM_STRINGS = 100\n",
    "# Setup a list of processes that we want to run\n",
    "processes = []\n",
    "for _ in range(NUM_STRINGS):\n",
    "    p = multiprocessing.Process(target=rand_string, args=(5, output))\n",
    "    processes.append(p)\n",
    "\n",
    "# Run processes\n",
    "for p in processes:\n",
    "    p.start()\n",
    "\n",
    "# Exit the completed processes\n",
    "for p in processes:\n",
    "    p.join()\n",
    "\n",
    "# Get process results from the output queue\n",
    "before = time.time()\n",
    "results = [output.get() for p in processes]\n",
    "after = time.time()\n",
    "\n",
    "print('\\n')\n",
    "print(\"Generated {} strings in {} seconds\".format(NUM_STRINGS, after-before))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As you can see, the task runs more than five times faster in parallel than it does in serial"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## IV.Parallelism and HPC\n",
    "Parallelism is at the core of any HPC system. The way that HPC systems can be many hundreds of thousands of times faster than traditional systems is through massive parallelism. Some HPC systems have a total of many millions of cores, distributed among many systems (known as 'nodes'), as compared to the 4-8 of a standard modern desktop. This massive hardware parallelism, combined with some clever parallel algorithms, can lead to amazing processing power. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Example 1.4 - Monte Carlo Pi in Parallel\n",
    "In this example, we will compute pi through monte carlo approximation, similar to the way we did it before, except this time we will do it in parallel. As mentioned earlier, the monte carlo pi calculation is a very easily parallelized algorithm, and there should be a large speedup when it is run in parallel."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Defining parallel monte carlo pi calculation \n",
    "\n",
    "import random\n",
    "import multiprocessing\n",
    "from multiprocessing import Pool\n",
    "\n",
    "\n",
    "#caculate the number of points in the unit circle\n",
    "#out of n points\n",
    "def monte_carlo_pi_part(n):\n",
    "    \n",
    "    count = 0\n",
    "    for i in range(n):\n",
    "        x=random.random()\n",
    "        y=random.random()\n",
    "        \n",
    "        # if it is within the unit circle\n",
    "        if x*x + y*y <= 1:\n",
    "            count=count+1\n",
    "        \n",
    "    #return\n",
    "    return count   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "You have 32 CPUs\n",
      "Esitmated value of Pi: 3.1416516 \n"
     ]
    }
   ],
   "source": [
    "# Calling parallel monte carlo pi simulation\n",
    "\n",
    "np = multiprocessing.cpu_count()\n",
    "print('You have {0:1d} CPUs'.format(np))\n",
    "\n",
    "# Nummber of points to use for the Pi estimation\n",
    "n = 10000000\n",
    "\n",
    "# iterable with a list of points to generate in each worker\n",
    "# each worker process gets n/np number of points to calculate Pi from\n",
    "\n",
    "part_count=[n//np for i in range(np)]\n",
    "\n",
    "#Create the worker pool\n",
    "# http://docs.python.org/library/multiprocessing.html#module-multiprocessing.pool\n",
    "pool = Pool(processes=np)   \n",
    "\n",
    "# parallel map\n",
    "count=pool.map(monte_carlo_pi_part, part_count)\n",
    "\n",
    "print(\"Esitmated value of Pi: {} \".format(sum(count)/(n*1.0)*4))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## V.Power and Speed Comparison\n",
    "One definition of HPC has to do with scale. Some people believe that an HPC system is defined by how powerful it is rather than by how it is designed. Computational power has increased an incredible amount recently and HPC scale systems are now easily accessible to many people. The following graphic shows how powerful modern systems can be: ![hpc system power comparison](https://i.imgur.com/frXsxpz.png)\n",
    "\n",
    "As you might guess, parallel algorithms have the potential to be much faster than serial algorithms. In order to show this, we are going to use the two versions of monte carlo pi that we have designed in this notebook and time them against each other. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Example 1.5 - Pi in Serial vs Parallel\n",
    "In this example, we will pit against each other our parallel and serial pi approximation calculations. To do this, we will use the jupyter \"magic\" `%time` to time the two algorithms."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Esitmated value of Pi: 3.158 \n",
      "CPU times: user 105 ms, sys: 839 ms, total: 943 ms\n",
      "Wall time: 712 ms\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Calling parallel monte carlo pi simulation\n",
    "\n",
    "# Nummber of points to use for the Pi estimation\n",
    "n = 10000\n",
    "\n",
    "# iterable with a list of points to generate in each worker\n",
    "# each worker process gets n/np number of points to calculate Pi from\n",
    "\n",
    "part_count=[n//np for i in range(np)]\n",
    "\n",
    "#Create the worker pool\n",
    "# http://docs.python.org/library/multiprocessing.html#module-multiprocessing.pool\n",
    "pool = Pool(processes=np)   \n",
    "\n",
    "# parallel map\n",
    "count=pool.map(monte_carlo_pi_part, part_count)\n",
    "\n",
    "print(\"Esitmated value of Pi: {} \".format(sum(count)/(n*1.0)*4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3.1624\n",
      "CPU times: user 11 ms, sys: 406 µs, total: 11.4 ms\n",
      "Wall time: 10.8 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "# Calling serial monte carlo pi simulation\n",
    "# Monte Carlo Pi Simulation\n",
    "import random as r\n",
    "import math as m\n",
    "\n",
    "# Number of darts that land inside.\n",
    "inside = 0\n",
    "# Total number of darts to throw.\n",
    "total = 10000\n",
    "\n",
    "# Iterate for the number of darts.\n",
    "for i in range(0, total):\n",
    "    # Generate random x, y in [0, 1].\n",
    "    x2 = r.random()**2\n",
    "    y2 = r.random()**2\n",
    "    # Increment if inside unit circle.\n",
    "    if m.sqrt(x2 + y2) < 1.0:\n",
    "        inside += 1\n",
    "\n",
    "# inside / total = pi / 4\n",
    "pi = (float(inside) / total) * 4\n",
    "\n",
    "# It works!\n",
    "print(pi)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## VI. HPC Architecture"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Example 1.6 - Pinging Other Nodes \n",
    "\"You're not alone out there\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercise 1. Write a program to compute sums of _n_ integers in parallel "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Your code goes here"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  },
  "latex_envs": {
   "LaTeX_envs_menu_present": true,
   "autoclose": false,
   "autocomplete": true,
   "bibliofile": "biblio.bib",
   "cite_by": "apalike",
   "current_citInitial": 1,
   "eqLabelWithNumbers": true,
   "eqNumInitial": 1,
   "hotkeys": {
    "equation": "Ctrl-E",
    "itemize": "Ctrl-I"
   },
   "labels_anchors": false,
   "latex_user_defs": false,
   "report_style_numbering": false,
   "user_envs_cfg": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
